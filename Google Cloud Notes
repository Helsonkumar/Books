Building Scalable Systems:
=========================================================
All systems are eventually consistent.

Performance has limit
Scalability has no limits.

Eventul consistency : If no updates then all part of the system would be eventually consistent.
Types: Consual Consistent , Strong Consistent , Sequential Consistent

All systems are eventual consistent in natre . Think of GitHub code locks.

Using locks would help us achieve Strong Consistency. Think of Single Db accessed by amny parts of the system.
But lock adds more overhead like contention.
Strogn consistency is all about diff parts of the system responding with the same answer if ased at any time.
All parts must agree upon the state and respond with answer like group of Jury.
Strong consistency mean we dont wnat to have STALE DATA.

Contention :  Diff parts of system contending for a shared resource like DB record,this would lead toa state where more the load is , higher the time taken to release the resource.


Consistency and Availability cannot co-exist.

Law of Scalabilty:
=====================
Amdahl's Law : Contention Limits parallelization. Depicts the relation between Concurrenty and Throughput of the system.

Defines the limits of parallelization.
Piece of code we can do nothing about is the one whihc holds contention and which cannot be parallelized.


Coherency Delay :
======================
Think of meeting scheduling scenarios.

**** Concurrency Vs Throughput ****

Gunther's Law of Coherency Delay :
-----------------------------------
Accounts for Contention + Coherency Delay.

State of Coherence : Can be achieved by having members of the system agreeing upon the state change of each other. 
                     But this would result in a delay.This is called Coherency delay.
					 
Gunther's Law states that increasing concurrency can result in negative result due to Coherency Delay + Contention.

Linear Scalability is almost not achievable : Considering the communication and Contention and Coherence verhead between the parts of the system.

Stateless : Cannot be achived. Sharing state between parts of system losses the ability of Linear Scalability.


How Reactive System / Microservice enhances Scalability :
===========================================================
Avoids Contention by :
    Isolating Locks,Elimates Txn , Avoids Blocking operation.
	
Avoids Coherency-Delay by :
    Embracing eventual consistency 
	Building Autonomy ==> Systems which do not have to interact
	
This simply reduces them and not avoids them.


CAP Theorem:
===============================================================
Consistency Availability Partition Tolerance

CA side is not a valid in kost cases....either CP or AP is possible..

Partition tolerance : When part of the system goes  down and unable to commnicate with each other the system still remains respnsive.
Partition does not mean the data partition. It means the node or system unvailability scenario.

Dealing with Partition : Making the system to remain responsive even under the case of drop of n/w comm
============================================================================================================
1. CP : Dropping the system which has gone down. So we write to one node and have that for read as well. Here the consistency is achived but if that single node goes down then we loss availability.
2. AP : Start writing on both the nodes. Here availability is achived , but consistency of data is achived since the data on both nodes would remain inconsistent.We will have to merge data after partition is resolved.

In reality, most systems balance the Consistency & Availability concerns usually favoring one side or the
other.

By doing all reads and writes through a single master node, we can guarantee: Consistency
When we failover to a replica, we are sacrificing: Consistency

By allowing reads and writes to go to any single database node, this system is favouring: Availability
Think of writig to all replicas before txn completes.... : Here we compromise availability...


Contention Vs Scalability:
============================
Consistency creates contention.
Contention will result in demnishing result in Scalability

Isolating  Contention :
============================
In Reactive Apps Shardign at APP level ;; Not the Db level
Record level locking instead of table level locking.

To provide scalability, while maintaining Consistency we look to: Isolate resource of contention

Sharding for Consistency : Provides Strong consistency
----------------------------------------------------------
Nodes has many Shards  ==> A Shard consist of many Entities.


A shard cannot exist in more than one node.
An entity cannot locate in more than one shard.

Query for an entitiy is decided by entity ID.
We use HashCode algo on entity ID to decide the shard to which that entity belongs.
Choosing correct enity ID is very important.

Sharding at the application level provides which of the following benefits:
----------------------------------------------------------------------------
Here even if the Db does not supports sharding we can still do sharding at app level.
Reduced comm between App and DB.
Strong Consistency
Improved Scalability.

We can describe Sharding by saying that: Sharding partitions(Nodes) entities or actors in the domain according to their unique Id. correct

Sharding Co-ordinator will ensure proper routing of the Entity request.

Thumb Rule is to get 10 Shards in a Node.

Effects of Sharding:
------------------------
Sharding isolates the contention to specific entities. The entities decides the contention boundry.
In a Sharded system, Strong Consistency is achieved by: Isolating operations to a specific entity, which processes one message/request  at a time

Sharding , Consistency , Scalability :
---------------------------------------
1. Scalability is acheived by distributing shards across nodes.
2. Strong Consistency is acheived by isolating operation to specific entities.
3. Careful choice of shard keys is imp to maintain good scalability.
4. Sharding help reducing Contention. It does not eliminates it though.
5. Sharding is a CP solution so it sacrifies Availability.

Caching with Shards ;
----------------------------
Consistent image of data is cache and Db is essesntial.
So we update DB and write the same to Cache.
This makes we barely use DB for reading. We use that only for writitng.
Since most of the apps are read heavy,,this optimizes the app to greater extent.


Availaility and Scalability:
------------------------------
CRDT : Conflict Free Replicated DataTypes


CRDTs for Availabiity : At App level
----------------------------------------
CvRDT and CmRDT
CvRDT is widely supported.

CvRDT : Ensures High Availability and Eventual Consistency

With CRDTs write happns in all nodes or replicas. And eventually merged to the final State.

Merge operation must be Commutative , Associative , Idempotent(Duplicate processign should not impact our result).

You can create custom CRDTs as long as you can define a merge operation.


Effects of CRDTs;
=====================
Map , Set , Conts can be used for CRDT...Tombstone(marker to denote deleted data : This increases the CRDT size)

Dist Data is primarily an availability Solution which is Eventually Consistent.
Note : We mean Dist Data , not Dist System

Read/Write Consistency in Distributed Data allows you to: Tune your solution towards Consistency, but away from Availability.


Consistency or Availability:
------------------------------
CAP Theorem forces us to have either Consistency or Availability :
Choise must be made at Business Level not at technical level

Factor out with Doamin experts on : Unavailable vs Eventual Consistent.

Within the same application or system, we sometimes need consistency, and other times need availability, depending on the use case.




CQRS Pattern :
=======================================================
Make sure if that is necessary. It should not be an overkill for us.
CQRS makes system : highly Scalable and Resilient.

You should consider using CQRS/ES if: You need auditability , You need additional resilience or scalability.

State Based Persistence :
-----------------------------
Saving latest state in DB rather than the way how it reached that state.it means persisence of destination alone rather than the journey(intent)

Disadvantage:
-----------------
Only the latest state can be viewed.
The corrupted state cannot be fixed.


Event Sourcing:
-----------------
1. For new domain insights.
2. We can replay events from history.

When using State Based Persistence, in order to recover from errors in state, or evolve our domain we can: Persist an audit log alongside our state so we understand where the state came from. 

When an audit log is stored alongside the state, we must be wary of which of the following: The audit log and the state must be updated in a transactional way.

A snapshot should be created: When the time to restore from the log is becoming excessive.

If you need to evolve your data model, you should do so by: Creating a new version of the event

Command Sourcing : Persist the commands instead of events.
But commands must be idempotent.
We need to validate the commands before persisting them. 

the problem that we have encountered with these conflicting models is:
  A model that is optimized for writes (Commands) may not be optimized for reads (Queries).
  
  
CQRS : Command Query Responsiblity Seperation Model:
=====================================================
using the same DB model for read and write load is difficult sometimes.
The aggregates that we use for write load does not match the needs for read load. Would not be higly performant.

Most applications tend to have:  More reads than writes.

So idea is to write(commnds) in a write model9DB / Data store) and then create projections  as per the requirement in the read model(Query == In Denormalized form  : Think of Reservation on Custormer ID based.)
Each model can be independentaly optimized or scaled.


An ideal read model is often setup so the data can be read directly from a single table in the database, as is, with minimal additional processing/formatting.

Polyglot Persistence means: Using different databases within your system, depending on the use case

A key benefit to combining CQRS and Event Sourcing is:
 The presence of the event log allows all new projections to be retroactive.
 The read and write models are decoupled, allowing them to evolve independently.
 The read and write models can be optimized individually, depending on their needs.
 







************************************************************************************************************************************************************************************************************************************
************************************************************************************************************************************************************************************************************************************
************************************************************************************************************************************************************************************************************************************
                                                                                     Google Cloud 
																			================================
																			
																			
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                                                                                    GENERAL NOTES
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
** We can manipulate tge GCP res using gcloud SDK , API lib , Consle


** Cloud SDK must be installed in local machine to access a VM instance or any GCP service from local machine.
   Then run gcloud --commnd in the sdk console to manipulate the GCP resources from your local machine
   run glcoud init ==> to set up the project and do anything
   gcloud compute instance list
   gcloud compute ssh "instance_name"  ==> connects to the given VM instance using ssh putty
   
   
**  Always enable the API for any service which you need to access.












------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	
Check for Google Cloud Products:
----------------------------------
https://cloud.google.com/products

Phase 1: Experiment with a Microservices Deployement with the below products
------------------------------------------------------------------------------
Compute         : Compute Engine  + App Engine

Containers      : GKE  + GKE Monitoring

Databases       : BigTable + MemoryStore + Cloud SQL

API Management  : Apigee + Cloud Endpoints

Serverless      : Cloud Functions + Cloud Run

Networking      : Cloud Load Balancing + Cloud Monitoring + Cloud Logging


Security Challenges with Cloud  : IS APP Dev
=================================================
Characteristics of Cloud  :
-----------------------------
1. On demand and Self Service
2. Broad Network accesse
3. Resource pooling
4. Rapid Elasticity
5. measured Sercvice  : Does not have to be infinite in elastic. setting up threshold for service monitoring.


Cloud Service Model :
---------------------------
IaaS : 
=======
only hardware is provisioned and the network firewall things are taken care.
user has control over Apps and OS and Application Firewall and Runtime like Web or App server.


PaaS : Serverless
======================
Customer controls only the App and Secure Data Access Controls.
The OS and rest are taken care by the vendor.


SaaS:
===================
Highest Level of Cloud Service model.
Customer has just the control over the deployed application which can leverage the cloud vendor's tools and technologies.
Can do the config changes to the underlying application hosting environments.
More secured than the self managed one since we have dedicated team to do the security checks for the hosted software.


Deployement Model :
=======================
Private Cloud : Strong control over the env like static Ip assignment etc
Community Model : 
Public Cloud
Hybrid Cloud




Google Cloud products :
=============================================================================================================
                                         COMPUTE ENGINE  
=============================================================================================================

VIRTUAL MACHINE RUNNIG IN GOOGLE CLOUD DATACENTER

General purpose (E2, N1, N2, N2D) machines provide a good balance of price and performance
Compute optimized (C2) machines offer high-end vCPU performance for compute-intensive workloads
Memory optimized (M2) machines offer the highest memory and are great for in-memory databases
Accelerator optimized (A2) machines are based on the A100 GPU, for very demanding applications	

Choosing the right machine family and type:
-------------------------------------------------
General purpose - These machines balance price and performance and are suitable for most workloads including databases, development and testing environments, web applications, and mobile gaming.

Compute-optimized - These machines provide the highest performance per core on Compute Engine and are optimized for compute-intensive workloads, such as high performance computing (HPC), game servers, and latency-sensitive API serving.

Memory-optimized - These machines offer the highest memory configurations across our VM families with up to 12 TB for a single instance. They are well-suited for memory-intensive workloads such as large in-memory databases like SAP HANA and in-memory data analytics workloads.

Accelerator-optimized - These machines are based on the NVIDIA Ampere A100 Tensor Core GPU. With up to 16 GPUs in a single VM, these machines are suitable for demanding workloads like CUDA-enabled machine learning (ML) training and inference, and HPC. 


These are the avilable families  : Under each families we would many machine types.

We would have multiple VM instance running in one Host with Hypervisor. So for diff user each VM instance belongs to one user each. Just visualize it.



General purpose family :
---------------------------
E2 offers the lowest total cost of ownership.
Offer up to 32 vCPUs and 128GB of memory per node
E2 machine types also leverage dynamic resource management,
If you have workloads such as web serving, small-to-medium databases, and application development and testing environments 
that run well on N1 but don’t require large instance sizes, GPUs or local SSD, consider moving them to E2.



N2 introduced the 2nd Generation Intel Xeon Scalable Processors 
offer a greater than 20% price-performance improvement for many workloads and support up to 25% more memory per vCPU.
run at 2.8GHz base frequency, and 3.4GHz sustained all-core turbo, offer up to 80 vCPUs and 640GB of memory. 
This makes them a great fit for many general purpose workloads that can benefit from increased per core performance, 
Including web and application servers, enterprise applications, gaming servers, content and collaboration systems, and most databases.
Whether you are running a business critical database or an interactive web application, N2 VMs offer you the ability to get ~30% higher performance from your VMs,
N2 instances perform 2.82x faster than N1 instances on AI inference of a Wide & Deep model using Intel-optimized Tensorflow, 



N2D VMs are built on the latest 2nd Gen AMD EPYC (Rome) CPUs, and support the highest core count and memory of any general-purpose Compute Engine VM
same features as N2 VMs including local SSD, custom machine types, and transparent maintenance through live migration.
N2D VMs provide performance improvements for data management workloads that leverage AMD’s HIGHER MEMORY BANDWIDTH and higher per-system throughput 
with up to 224 vCPUs, making them the largest general purpose VM on Google Compute Engine.
N2D machine types are suitable for web applications, databases, workloads, and video streaming.
USEFUL FOR STREAMING , making them a great fit for memory bandwidth-hungry applications.



N1s are first-generation general purpose VMs and offer up to 96 vCPUs and 624GB of memory 
For GPU workloads, N1 supports a variety of NVIDIA GPUs


Second generation is highly recommneded.

For flexibility, general purpose machines come as predefined (with a preset number of vCPUs and memory), or can be configured as custom machine types
Custom machine types allow you to independently configure CPU and memory to find the right balance for your application,




Compute-optimized (C2) family:
----------------------------------
Compute-optimized machines focus on the highest performance per core and the most consistent performance to support real-time applications performance needs. 
offering up to 3.8 GHz sustained all-core turbo, these VMs are optimized for compute-intensive workloads such as HPC, gaming (AAA game servers), and high-performance web serving.
produce a greater than 40% performance improvement compared to the previous generation N1
offer higher performance per thread and isolation for latency-sensitive workloads
Compute-optimized VMs come in different shapes ranging from 4 to 60 vCPUs, and offer up to 240 GB of memory.
You can choose to attach up to 3TB of local storage to these VMs for applications that require higher storage performance. 
Whether you are optimizing for the number of queries per second or the throughput of your map routing algorithms
 
 
 
 
Memory-optimized (M1, M2) family :
--------------------------------------
Memory-optimized machine types offer the highest memory in our VM family
from 1TB to 12TBs of memory, and offer up to 416 vCPUs,
these VMs offer the most compute and memory resources of any Compute Engine VM offering.
They are well suited for large in-memory databases such as SAP HANA, as well as in-memory data analytics workloads
M1 VMs offer up to 4TB of memory, while M2 VMs support up to 12TB of memory.
making them a great choice for workloads that utilize higher memory configurations with low compute resources requirements.




Accelerator-optimized (A2) family:
-----------------------------------------
designed to meet today’s most demanding applications such as machine learning and HPC. 
A2 VMs were the first NVIDIA Ampere A100 Tensor Core GPU-based offering on a public cloud.
Each A100 GPU offers up to 20x the compute performance compared to the previous generation GPU and comes with 40GB of high-performance HBM2 GPU memory.
