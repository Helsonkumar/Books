Spark Notes :
=====================

Check what is zero-copy clone
Is predicate push down applicable in all cases.












Spark uses Hadoop‚Äôs client libraries for HDFS and YARN.
We have Hadoop free binary version as well.
Spark runs on both Windows and UNIX-like systems (e.g. Linux, Mac OS), and it should run on any platform that runs a supported version of Java.
Spark runs on Java 8/11, Scala 2.12, Python 2.7+/3.4+ and R 3.5+. 
For the Scala API, Spark 3.0.1 uses Scala 2.12. You will need to use a compatible Scala version (2.12.x).
Apache Spark uses Arrow as a data interchange format, The Arrow format is designed to enable fast computation.
Apache Arrow defines a language-independent columnar memory format for flat and hierarchical data, organized for efficient analytic operations on modern hardware like CPUs and GPUs. 


Cluster Mode  : Driver(with Sc) runs within the Application Master process which inturn runs in side the cluster-scoped
it is common to use cluster mode to minimize network latency between the drivers and the executors.


Client Mode   : Driver runs inside the spark-submit(Client to cluster) process and the application master simply exists to ask for resources from YARN.The input and output of the application is attached to the console.
Thus, this mode is especially suitable for applications that involve the REPL (e.g. Spark shell).
use this mode if your client is physically colocated to the worker node since the worker talks to master during app execution

‚Äì In YARN cluster mode, the Driver is run on YARN Application Master run on random Core node )
‚Äì IN YARN Client  Mode, the Driver is run on Master node itself. Bcz the the driver runs inside the yarn client process which is launched in Master node. 


In Cluster mode  : A YARN Client process is created and it periodically polls the APP Master.

When log aggretaion is truend on you eill see all logs for all executors and driver in the console with the below commnd: Else we will have the go the Data node and check for the logs with the app-id /var/log/hadoop-yarn/containers/[application id]/[container id]/stdout
yarn logs -applicationId <app ID>


Config Commands  :
----------------------
--jars : to have the dependcy jars distributed among the executors classpath.This is meant to be a dependcy jars for all task submitted to cluster.
--files  : Custome fiels to be used in executors (like log4J properties).This willl be uploaded from local Fs to HDFS and then loaded to executors

/bin/spark-submit \
  --class <main-class> \
  --master <master-url> \
  --deploy-mode <deploy-mode> \
  --conf <key>=<value> \
  ... # other options
  --jars/ --files
  <application-jar> \
  [application-arguments]
  
  Config :
  sparkContext.setConf / --conf flags / spark-defaults.conf

Advanced Dependency Management
When using spark-submit, the application jar along with any jars included with the --jars option will be automatically transferred to the cluster and these jars would be copied or cached to the driver and workers involved..

File:// ==> means the drivers https file server (the executors pull the jar form this location )
hdfs://, https://, https:// ==> straightforward
local:/// ==> the file is expected to be present in all worker nodes(useful if large jars need to be transferred.Reduce network IO)
Note that JARs and files are copied to the working directory for each SparkContext on the executor nodes.
With YARN, cleanup is handled automatically for these jars after app execution.




SparkUI : Is hosted by Driver node(WHIHC MATY BE RANDOM NODE). So u must go to the driver node.
Spark History server  : Basically hosted in masternode :18080


Spark infact needs kerbros token to access various Cluster service to do the job. Even the Oozie workflow must be enabled to collect such token



Caught from High performance spark :
---------------------------------------------
Spark infact needs a storage system and clustre manager.

The cluster manager simply allocates resources and launches the executor according to the config setup and orchestrates them.

RDD  : Lazily evaluated  , Immutable , In-Memory

Lay evaluation  : helps us collate or combine operation that does not require comm to driver and execute them in single pass thru of data.
we can chain together operations with narrow dependencies and let the
Spark evaluation engine do the work of consolidating them.

Fault Tolerant  : Spark would bnot privde incorrect result in the event of host machine failure.
Bcz each partiton has its own dependcy info to recalculate them if lost.

An RDD interface has 5 major properties  : List of partitons , Dependent partitions , fucntion for iteraor , partitioner , Prefered location (gives the lcoation info)

Sparkís performance advantage over MapReduce is greatest in use cases involving
repeated computations.
In mapreduce the intermediate result is wirriten to disk for each pas thru of data.

Option for mem-mgmt :
----------------------
Inmemory deserialized : data is stored in the memory in the form of object. CPU efficine t. But not memory effective.
In-memory Serialized : Objects in RDD in the form of deserialized stream of bytes.
On Disk  : RDD partitons too lrage can be stored in disk.but can be more fault-tolerant for long sequences of
transformations


A spark action triggers a job.
A job has a stage defined for each txn with wide dependency
Each stage has set of tasks (assigned to Task Scheduler in each node)

Narrow and Wide dependency

Narrow  : A parent has only one child.
Wide  : A parent has many child

Dependencies are explianed from parent perspective.

Wide Dep : Due to shuffle
happens for K,V paired data types.
During every shuffle we talk with driver.
Txns with narrow dependency can be clubbed togther and doen within one data pass thru.
This would result in good performance  
The no of task depends on the number of partition involved in the child partition.
Shuffles stages limit the parallelization.results in Disk IO for shuffle files and data movement
Partiton with wide dependecny has costly in being recomputiing since most of its child partition must be recomputed again.

Coalesce : is used to change the number of partitions in an RDD .  It might decrease or increase the partition number.
its a Narrow one when we decrease the number, It does not triggeres shuffle.
it is wide when we increase the number of partition.
Increasing the parttion number triggeres the shuffle and this is a wide txn.
Note  : Shuffle is triggered for Non K.V paired data as well. Coalesce and Repartition is a special case.
U can set shuffle true oro flase for coalesce

Repartiton  : is an alternate to coalesce. It triggeres shuffle.

For partiton increase prefer repartition over coalesce.

RDD type information is very imp. 

Take care of GC. GC triggers more serialization time.Avoid creating more objects.

Tip : Try reusing the same object instaed of creating a new object for every records read like we did in the aggregate scala example.
Means we need to use mutable objects.
But best to avoid using mutable objects in spark since they might lead to serlaization error and provide inaccurate result.

Serialization in spark :
==========================
The compiled code  (Static part ) of the code is transfered to the driver and the worker. This does not happen during the run time.
But during the runtime the reference to objects (instance of class) is passed to the worker from teh driver.
This is what the serialization during the runtime. This can cause the tassk not serializable error during runtime.

References to static parts of the code. These point to things that were established permanently during compilation, and have already been shipped to the workers.
References to objects ‚Äî instances of classes. These were created by the driver at runtime, hence the workers have no copy of them. These must be serialized and shipped to the workers.











For Spark SQL  : The fulcrum is the "DataSource API". So any format of data can be analyzed. 
So user must implement a plugin using this DataSource API to analyze a custom formatted data.

RDD , DataFrame,  SQL

RDD is not used these days since it is cumbersome.

DF and SQL are Structured API.
But they limit what can be expresssed. 
But they make the code more Declarative and More space for optimization (here where the Catalyst Optimizer comes into the picture)


SQL : Catalyst optimizer
==============================
How catalyst work:
-------------------- 
Analysis Phase:                                           Optimization Phase:                     Physical Planning                              Code Generation  (Converst the Physical plan into specialized Java code )
====================                                     =======================                 =========================                    =========================
Unresolved Logical Plan  ===> Resolved Logical Plan ===>  Optimzed Logical Plan   ===> Physical plans ===> Cost based model ==> Selected Physical plan       ====> RDD  ====> Result


Physcial plan  : Cost based model  : Its does smoething like Join Selection
 But rite now we dont do consideration of diff rules for cost optimization.
 Instead we currently generate only one Physical plan and we stck to that.
 
*** Step 1: User code is abstracted as Tree despite of the language in whihc it is written

*** Step 2  : Transformation  : Logical plan to physical plan (using strategies) Implemented using Scala partial function and Pattern matching.

Logical plan : Defines the computation on the data w/o defining how to conduct such computation.

Rule are applied  : Rules are something like doing only Row Projection and Column Pruning.

so these rules are applied in batches to batch of rows.

Looks like the data layer or storage layer statictics is very imprtatnt to decode the effective query plan.

But the storage layer statistics may change at nay point of time and it is out of Spark's control

So Databricks brought in 2 solutions: Delta lake and AQE

Delta lake  : Gives ACID model on Spark data. It is an open source storage layer. Better optimization oppurtunities.
 
 
 SHUFFLE  or BROADCAST divides the query execution into stages.
 Intermediate results are materialized at the end of query stages. (Query stages points are the pipeline break point)
 Query stage point is optimal for runtime optimization.
 
 Unlike WE HAVE BEEN THOGUTH, intermediate results between stages are written to Disk, so the optimal size of the data is calculated for the AQE.
 
 So the query plan is re-calculated at the end of every stages.
 
 Effect of partition being too small and too large :
 ===================================================
 GC pressure, disk spill
 inefficient IO , Scheduler overhead , task setup
 
 Effect of Skew join or Skew data in general
 ================================================
 long running task for a stage among list of tasks.
 Disk spilling.
 
 
 
 
 
 

AQE  : Adaptive Query Execution in Spark 3.0
=================================================
It simply optimizez the layer between logical and Physical plan dynamically by using the runtime metrics of the stages involved in the spark pipeline.

At present, the following optimizations have been implemented in version 3.0:

****Dynamically coalescing shuffle partitions : Earlier it use to be a static one. But now it can be dynamic.
****Dynamically switching join strategies
****Dynamically optimizing skew joins

Dynamically coalescing shuffle partitions
------------------------------------------
Transformations on a dataset deployed on Spark can be of two types: narrow or wide

Wide-type data needs partition data to be redistributed differently between executors to be completed. 
e.g groupBy operation . Joins ,etc

The number of partitions after optimization will depend instead on the setting of the following configuration options:
spark.sql.adaptive.coalescePartitions.initialPartitionNum
spark.sql.adaptive.coalescePartitions.minPartitionNum
spark.sql.adaptive.advisoryPartitionSizeInBytes

where the first represents the starting number of partitions (default: spark.sql.shuffle.partitions), 
the second represents the minimum number of partitions after optimization (default: spark.default.parallelism), and 
the third represents the ‚Äúsuggested‚Äù size of the partitions after optimization (default: 64 Mb).


Joins  :
=====================
Joins in spark is expensive due to shuffles files.
if the datasets do not have known partitioner(partitioned with same partitioner) then we may have data (value for the same key) unevenly distributed acros nodes.
Ideal spark tends to collect data or value for a key present in the same partition or in the same node.
So the same key from 2 diff datasets would be made to present in the same node so the data for that key can be joined locally. This triggers the shuffling of files across network.
But if the datasets are already partitioned by the same partitioner then the values would present in the same node.Shuffle would not be triggered in this case.
Spark in geberal does the qui-join.ie.join only the keys whihc are rpresent in 2 DS.
Supports right-outer,left-outer,full-outer,left-semi,left-anti
Default  : Shuffle Hash join

Joins in RDD is not as optimized as Join in Datasets or Dataframes.
In Spark-sql the filetr push down and BC hash join ia all taken care by the optimizer.

Broadcast Hash join :
-------------------------
To avoid large shuffle, the smallest DS from a join would be completly broadcasted to the nodes related to the larger node.
This reduces network IO.

Static Partiton pruning :
-----------------------------
Used to consider only the partitons whihc are related to the join while scan.
if we use any of the partiton column for fileter then static pruning is triggered.

 
 
 

Dynamic Partition pruning  :
=================================

The mechnism for Spark to prune scanning unnecessary partitons in a query
This an optimization from Spark v3.0

Dynamic partition pruning occurs when the optimizer is unable to identify at parse time the partitions it has to eliminate. 

*** This optimization is triggerred only when your join query is planned as BROADCAST-HASH JOIN.
*** when one table in the join is below 10MB(treshold to consider a table as small to be used for Broadcasting)

This optimization occurs at the Logical Plan level.

This is useful for running effective  SATR SCHEMA JOIN queries : Queries which involve the big fact tables and multiple Small dimensional tables.

Lets say we join sales fact table with the date dim tale. And we have filter for Dim table alone .
Since the Dim table is small in size here , spark would do the broadcast jon .ie
The Filtered result from the Dim table is broadcasted to the nodes where the partiton for the fact table resides.
This would help us avaoid shuffles.

DPP uses this approache. 
The filtered applied on DIM tables is plugged into the scanner of the larger Fact tables, so only the fact partitions which are actually needed for joining would be scanned.
This is what DPP all about. 
We avoid scanning unnecessary scanning in Star-Schema join queries.

pre-requisite :
-------------------------
This would work only if there is a matching partition column between fact and dimension tables.
The size of the dim table must be uynder 10MB configured level. To be considered as Broadcast Hash join.
DPP is not triggered for other type of joins.
Because the dynamic filtering is a kind of subquery duplication. (subquery holds the filetered result of the dim table)
So as long as the Dim table subquery duplicate execution is cheaper, it is ok.
if the Subquery duplication is costly then spark would not triggere this DPP.




Imaging that dim has column date which is not a partition column in the fact table.
Then the entire fact tables would be scanned anyway , and the DPP is not applicable in this case.

This can be said as a challenge faced.

















Spark On Kubernetes: as of spark 3.0.1 version
=========================================================

To make the most of Apache Spark, we need two things:
A distributed storage to store the data
A scheduler to run the Spark executors across a computing cluster
People have been doing this differently on-premise and cloud. With on-premise, most use Spark with Hadoop, or particularly HDFS for the storage and YARN for the scheduler. While in the cloud, most use object storage like Amazon S3 for the storage, and a separate cloud-native service such as Amazon EMR or Databricks for the scheduler. 


Reason  :
-------------

In general Seperation of Storage and Computation is what needed. This is somewhat addressed by containerized apps in kubernetes.

The primitives offered by k8s like namepsaces, pods, deployment, raset,etc has been reason for running spark on k8s instead of yarn.

***Simpler Administration
    Kubernetes allows for the unification of infrastructure management under a single type of cluster for multiple workload types. You can run Spark, of course, 
	but you can also run Python or R code, notebooks ,and even webapps. 
	In the traditional Spark-on-YARN world, you need to have a dedicated Hadoop cluster for your Spark processing and something else for Python, R, etc.

Isolation, meaning that you can prevent workloads running in the cluster from interfering with each other because they will remain in their own "namespaces.‚Äù 


*** Better resource management,
    the scheduler takes care of picking which node(s) to deploy the workloads on in combination with the fact that in the cloud, scaling a cluster up/down is quick and easy 


***Easier Dependency Management across Workloads
   Managing dependencies in Hadoop is time-consuming: packages have to exist on all nodes in a cluster, 
   makes isolation (i.e., making different versions of the same software - like TensorFlow 1.5 and TensorFlow 2.0 - coexist on the same node) difficult and updating environments challenging.
   the hassle of maintaining a common dependency for all workloads running on a common infrastructure is removed due to docker containers with their onw dependencies.
   
   
***More Flexible Deployment
   If you‚Äôre doing Enterprise AI and want to start moving data storage to the cloud (or have already started doing so), the idea of vendor lock-in can be very scary. 
   That‚Äôs why today, more and more businesses are taking a cloud-agnostic approach.
   Running Spark on Kubernetes means building once and deploying anywhere, which makes a cloud-agnostic approach scalable.
   We dont have to refactor our CI/CD pipelines for each env like EMR, DataProc , HDInsight
   
   
*** It's Cheaper
       
	   
	   
Pitfalls:
-----------
Spark-submit is added with support to Kubernetes since v2.3. Supports both cluster and client(since 2.4) mode
But Kubernetes operator provides a lot more feature owing Monitoring and management.
Although easy to use, spark-submit lacks functionalities like supporting basic operations for job management. 
 Thus, users will have to manage their jobs via the Kubernetes tools like kubectl in this case.
 
The Spark driver pod uses a Kubernetes service account to access the Kubernetes API server to create and watch executor pods.
By default, the driver pod is automatically assigned the default service account in the namespace specified by spark.kubernetes.namespace
if no service account is specified when the pod gets created else it uses : spark.kubernetes.authenticate.driver.serviceAccountName=<service account name>.

$ kubectl create serviceaccount spark
To grant a service account a Role or ClusterRole, a RoleBinding or ClusterRoleBinding is needed. 

Note that a Role can only be used to grant access to resources (like pods) within a single namespace,
whereas a ClusterRole can be used to grant access to cluster-scoped resources (like nodes) as well as namespaced resources (like pods) across all namespaces.

 
spark-submit vs operators:
-------------------------------
Client mode :spark-submit directly runs the driver at the spark-submit submission client side or within Pod and the executors run as pods in the kubernetes cluster
Cluster-mode : spark-submit delegates the job submission to kuberntes spark backend service whihc runs the driver in a pod.

We dont need spark pre-installed in the k8s nodes, since the spark version is decided by the spark-submit we use and the requireed spark core version is actually bundled on fly in the respective containers.
**So we can run app-spark2.4 and app-spark2.5 version simultaneously without any issues in the same k8s cluster in the same namepsace as well.



Dependency management in k8s :
------------------------------------
The application dependencies: Can be done in 2 ways
    They can be bundled into the container image itself (like uber jar)
	They can be passed as SPARK_EXTRA_CLASSPATH var inside the dockerfile used to build the application image or via local:/// . These app dependencies would be downloaded and added to driver pods classpath during run time.
	
	


The driver then interacts with K8s api-server for creation and management of the executors pods.
In spark submit everyting is driven by configuration properties (--conf)

spark-submit can be directly used to submit a Spark application to a Kubernetes cluster. The submission mechanism works as follows:
It comminucates with the k8s cluster thru a K8 clinet interface which can be customized


Spark creates a Spark driver running within a Kubernetes pod.
The driver creates executors which are also running within Kubernetes pods and connects to them, and executes application code.
When the application completes, the executor pods terminate and are cleaned up, but the driver pod persists logs and remains in ‚Äúcompleted‚Äù state in the Kubernetes API until it‚Äôs eventually garbage collected or manually cleaned up.

POD Template :
----------------
Spark can be provided with config for Driver and Executor pods using pod template.

spark.kubernetes.driver.podTemplateFile 
spark.kubernetes.executor.podTemplateFile

the pod templates are used for the customization of driver and executor pods.
A spark pod can contain spec for more than one container.
 To allow the driver pod access the executor pod template file, the file will be automatically mounted onto a volume in the driver pod when it‚Äôs created.


Using Kubernetes Volumes:
----------------------------
Spark on Kubernetes in general interacts with Object Storage like GCS or AWS S3 or any other form of NFS for data storage read and writes.
The HDFS integration is still experimental.
So the IO is not effective here.
Also spark uses some scrtach psace to store the tmpFS for spill files.
Using DockerFS is slower.///So we use Volumes to hold these temp files


Starting with Spark 2.4.0, users can mount the following types of Kubernetes volumes into the driver and executor pods:
***hostPath: mounts a file or directory from the host node‚Äôs filesystem into a pod.(like host SSD)
***emptyDir: an initially empty volume created when a pod is assigned to a node. (This is part of nodes volume(temp volume)
             By default emptydir is created for each pod.
			 emptyDir volumes use the nodes backing storage for ephemeral storage by default,
			 
***persistentVolumeClaim: used to mount a PersistentVolume into a pod.
***RAM : Even RAM can be used for any diskless nodes.. But this is dangerous of loosing spill data.
         This part is alos considered while allocating memory for pods.
		 
--conf spark.kubernetes.driver.volumes.[VolumeType].[VolumeName].mount.path=<mount path>



Local Storage  :
---------------
spark.local.dir  : Used for data spills during shuffles.


Using RAM for local storage:
-------------------------------
For example if you have diskless nodes with remote storage mounted over a network, having lots of executors doing IO to this remote storage may actually degrade performance.
In this case it may be desirable to set spark.kubernetes.local.dirs.tmpfs=true in your configuration which will cause the emptyDir volumes to be configured as tmpfs i.e. RAM backed volumes.


Introspection and Debugging:
---------------------------------
Accessing Logs : kubectl -n=<namespace> logs -f <driver-pod-name>
                 or used Kubernetes Dashboard


Accessing Driver UI : $ kubectl port-forward <driver-pod-name> 4040:4040
Then, the Spark driver UI can be accessed on http://localhost:4040.


Debugging :  often, the best way to investigate may be through the Kubernetes CLI.
$ kubectl describe pod <spark-driver-pod>
$ kubectl logs <spark-driver-pod>

***Finally, deleting the driver pod will clean up the entire spark application, including all executors, associated service, etc. 
***The driver pod can be thought of as the Kubernetes representation of the Spark application.


Kubernetes Features
============================
Configuration File :
---------------------


Context  :
----------- 
Used to switch between multiple k8s cluster



Namespaces :
--------------
 Namespaces are ways to divide cluster resources between multiple users (via resource quota).
 Kubernetes allows using ResourceQuota to set limits on resources, number of objects, etc on individual namespaces. 
 
 





Spark Application Management:
=================================
Users can kill a job by providing the submission ID that is printed when submitting their job. 
 The submission ID follows the format namespace:driver-pod-name.
 
 $ spark-submit --kill spark:spark-pi-1547948636094-driver --master k8s://https://192.168.2.8:8443
 $ spark-submit --status spark:spark-pi-1547948636094-driver --master  k8s://https://192.168.2.8:8443



Future Work:
------------------
There are several Spark on Kubernetes features that are currently being worked on or planned to be worked on. Those features are expected to eventually make it into future versions of the spark-kubernetes integration.

Some of these include:

Dynamic Resource Allocation and External Shuffle Service : The shuffles files are lost whne the excutor node is scaled down in Dynamic allocation.
This is prevented by using the external shuffle service to external files systems.This saves even the scratch data which spark writes locally.


Scaling can be at App level or even at cluster level in K8s.
spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.shuffleTracking.enabled=true

but in Dynamic Scaling the node start may take some time.
To kick start the pods immediately, you can oversize your Kubernetes cluster by scheduling what is called ‚Äúpause pods‚Äù on it. 
These are low-priority pods which basically do nothing.
When a Spark app requires space to run, Kubernetes will delete these lower priority pods, and then reschedule them 
This prevent starting a new node and consumes no resource for pause pods.


Use on Demand machines for Drivers and Spot nodes for executors.



Job Queues and Resource Management



Spark Opeartors:
---------------------
based on operator pattern.
Which encapsulates the domain knowledge of running spark app with custom resources and the defines controllers for those resources.

The Operator defines two Custom Resource Definitions (CRDs), SparkApplication and ScheduledSparkApplication.
The later is for submitting spark jobs as per a timly schedule like schdule cron job
the Operator also gives you the ability to mount volumes and ConfigMaps to customize your pods.
In Operator everytiing is defined in the form of yaml file and have them deployed.
So that the spark driver and its relevant objects can be managed as a normal kube objects. 

So we need to have the Spark Opeartor installed in the kubernetes cluster first.
So it creates a custom controllers.
The job definition in the yml file defines the spark job object.
Once the yml file is submitted the operator calls the custom controller to create a Spark job object from the given job def in yml file
And then the componenets within the operator submits the spark-submit command.
The pods events are monitored by the component within the Opeartor pod.


What Is A Mutating Admission Webhook?
The webhook supports mounting ConfigMaps in Spark pods, which can come in handy in the following scenarios:















